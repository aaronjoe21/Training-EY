{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NyV1zqEM8bWX"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"CustomerAnalysis\").getOrCreate()"
      ],
      "metadata": {
        "id": "XhDgDqOcAOiD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 1\n"
      ],
      "metadata": {
        "id": "MfThRQ2x8r84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Read orders.csv as all StringType\n",
        "schema = StructType([\n",
        "    StructField(\"order_id\", StringType(), True),\n",
        "    StructField(\"customer_id\", StringType(), True),\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"category\", StringType(), True),\n",
        "    StructField(\"product\", StringType(), True),\n",
        "    StructField(\"amount\", StringType(), True),\n",
        "    StructField(\"order_date\", StringType(), True),\n",
        "    StructField(\"status\", StringType(), True)\n",
        "])\n",
        "\n",
        "orders_df = spark.read.csv(\"orders.csv\", header=True, schema=schema)\n",
        "\n",
        "# 2. Trim text columns\n",
        "orders_df = orders_df.select([trim(col(c)).alias(c) for c in orders_df.columns])\n",
        "\n",
        "# 3. Normalize city, category, product\n",
        "orders_df = orders_df.withColumn(\"city\", lower(col(\"city\"))) \\\n",
        "                     .withColumn(\"category\", lower(col(\"category\"))) \\\n",
        "                     .withColumn(\"product\", lower(col(\"product\")))\n",
        "\n",
        "# 4. Clean amount: Remove commas, Convert to IntegerType, Handle invalid values safely\n",
        "# First remove commas\n",
        "orders_df = orders_df.withColumn(\"amount_cleaned\", regexp_replace(col(\"amount\"), \",\", \"\"))\n",
        "\n",
        "# Use when + rlike to check if string is numeric before casting\n",
        "orders_df = orders_df.withColumn(\"amount\",\n",
        "    when(col(\"amount_cleaned\").rlike(\"^-?[0-9]+$\"), col(\"amount_cleaned\").cast(IntegerType()))\n",
        "    .otherwise(lit(None).cast(IntegerType()))\n",
        ").drop(\"amount_cleaned\")\n",
        "\n",
        "# 5. Parse order_date into DateType â†’ order_date_clean (handle multiple formats safely)\n",
        "# Replace / with - first to normalize\n",
        "orders_df = orders_df.withColumn(\"date_normalized\", regexp_replace(col(\"order_date\"), \"/\", \"-\"))\n",
        "\n",
        "# Try parsing with safe approach\n",
        "orders_df = orders_df.withColumn(\"order_date_clean\",\n",
        "    when(col(\"date_normalized\").rlike(\"^[0-9]{4}-[0-9]{2}-[0-9]{2}$\"),\n",
        "         to_date(col(\"date_normalized\"), \"yyyy-MM-dd\"))\n",
        "    .when(col(\"date_normalized\").rlike(\"^[0-9]{2}-[0-9]{2}-[0-9]{4}$\"),\n",
        "         to_date(col(\"date_normalized\"), \"dd-MM-yyyy\"))\n",
        "    .otherwise(lit(None).cast(DateType()))\n",
        ").drop(\"date_normalized\")\n",
        "\n",
        "# 6. Remove duplicate order_id\n",
        "orders_df = orders_df.dropDuplicates([\"order_id\"])\n",
        "\n",
        "# 7. Keep only Completed orders and filter out null amounts and dates\n",
        "clean_orders_df = orders_df.filter(\n",
        "    (lower(col(\"status\")) == \"completed\") &\n",
        "    (col(\"amount\").isNotNull()) &\n",
        "    (col(\"order_date_clean\").isNotNull())\n",
        ")\n",
        "\n",
        "clean_orders_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6oFXBtXBwU9",
        "outputId": "ef0cd22b-946e-4484-876a-8967f290be94"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------------+\n",
            "|   order_id|customer_id|     city|   category|product|amount|order_date|   status|order_date_clean|\n",
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------------+\n",
            "|ORD00000001|    C000001|     pune|    grocery|  sugar| 35430|2024-01-02|Completed|      2024-01-02|\n",
            "|ORD00000007|    C000007|     pune|    grocery|   rice| 45362|2024-01-08|Completed|      2024-01-08|\n",
            "|ORD00000008|    C000008|bangalore|    fashion|  jeans| 10563|2024-01-09|Completed|      2024-01-09|\n",
            "|ORD00000010|    C000010|bangalore|    grocery|  sugar| 66576|2024-01-11|Completed|      2024-01-11|\n",
            "|ORD00000011|    C000011|  kolkata|electronics| tablet| 50318|12/01/2024|Completed|      2024-01-12|\n",
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 2"
      ],
      "metadata": {
        "id": "3LhbmWa986KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Total number of orders.\n",
        "#2. Total spending.\n",
        "#3. Average order value.\n",
        "#4. First purchase date.\n",
        "#5. Last purchase date.\n",
        "#6. Number of distinct cities ordered from.\n",
        "#7. Number of distinct categories ordered from.\n",
        "\n",
        "customer_metrics = clean_orders_df.groupBy(\"customer_id\").agg(\n",
        "    count(\"order_id\").alias(\"total_orders\"),\n",
        "    sum(\"amount\").alias(\"total_spending\"),\n",
        "    avg(\"amount\").alias(\"avg_order_value\"),\n",
        "    min(\"order_date_clean\").alias(\"first_purchase_date\"),\n",
        "    max(\"order_date_clean\").alias(\"last_purchase_date\"),\n",
        "    count_distinct(col(\"city\")).alias(\"distinct_cities\"),\n",
        "    count_distinct(col(\"category\")).alias(\"distinct_categories\")\n",
        ")\n",
        "\n",
        "customer_metrics.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJTc2zhM9Ckf",
        "outputId": "a0bfae89-3446-4129-a1f8-eeb113023276"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+--------------+------------------+-------------------+------------------+---------------+-------------------+\n",
            "|customer_id|total_orders|total_spending|   avg_order_value|first_purchase_date|last_purchase_date|distinct_cities|distinct_categories|\n",
            "+-----------+------------+--------------+------------------+-------------------+------------------+---------------+-------------------+\n",
            "|    C018237|           4|        226546|           56636.5|         2024-01-18|        2024-02-27|              3|                  3|\n",
            "|    C044374|           6|        224785|37464.166666666664|         2024-01-15|        2024-02-24|              3|                  3|\n",
            "|    C001115|           5|        163614|           32722.8|         2024-01-16|        2024-02-25|              5|                  3|\n",
            "|    C012569|           6|        270399|           45066.5|         2024-01-10|        2024-02-19|              5|                  3|\n",
            "|    C010142|           5|        245547|           49109.4|         2024-01-03|        2024-02-12|              3|                  3|\n",
            "+-----------+------------+--------------+------------------+-------------------+------------------+---------------+-------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 3"
      ],
      "metadata": {
        "id": "PVb-db_39IMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_segments = customer_metrics.withColumn(\"customer_segment\",\n",
        "    when((col(\"total_spending\") >= 200000) & (col(\"total_orders\") >= 5), \"VIP\")\n",
        "    .when(col(\"total_spending\") >= 100000, \"Premium\")\n",
        "    .otherwise(\"Regular\")\n",
        ")\n",
        "\n",
        "customer_segments.show(5)\n",
        "\n",
        "# Count customers in each segment\n",
        "segment_counts = customer_segments.groupBy(\"customer_segment\").count()\n",
        "segment_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01CAH39p9LuG",
        "outputId": "b93188b3-5a27-4372-e1e2-ff5b67033e58"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+--------------+------------------+-------------------+------------------+---------------+-------------------+----------------+\n",
            "|customer_id|total_orders|total_spending|   avg_order_value|first_purchase_date|last_purchase_date|distinct_cities|distinct_categories|customer_segment|\n",
            "+-----------+------------+--------------+------------------+-------------------+------------------+---------------+-------------------+----------------+\n",
            "|    C018237|           4|        226546|           56636.5|         2024-01-18|        2024-02-27|              3|                  3|         Premium|\n",
            "|    C044374|           6|        224785|37464.166666666664|         2024-01-15|        2024-02-24|              3|                  3|             VIP|\n",
            "|    C001115|           5|        163614|           32722.8|         2024-01-16|        2024-02-25|              5|                  3|         Premium|\n",
            "|    C012569|           6|        270399|           45066.5|         2024-01-10|        2024-02-19|              5|                  3|             VIP|\n",
            "|    C010142|           5|        245547|           49109.4|         2024-01-03|        2024-02-12|              3|                  3|             VIP|\n",
            "+-----------+------------+--------------+------------------+-------------------+------------------+---------------+-------------------+----------------+\n",
            "only showing top 5 rows\n",
            "+----------------+-----+\n",
            "|customer_segment|count|\n",
            "+----------------+-----+\n",
            "|         Premium|13978|\n",
            "|         Regular|  707|\n",
            "|             VIP|32815|\n",
            "+----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 4"
      ],
      "metadata": {
        "id": "xES_egOp9K40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Rank customers by total spending (overall)\n",
        "overall_window = Window.orderBy(col(\"total_spending\").desc())\n",
        "ranked_customers = customer_segments.withColumn(\"overall_rank\", rank().over(overall_window))\n",
        "\n",
        "# 2. Rank customers inside each city by total spending\n",
        "city_data = clean_orders_df.groupBy(\"customer_id\", \"city\").agg(\n",
        "    sum(\"amount\").alias(\"city_spending\")\n",
        ")\n",
        "city_window = Window.partitionBy(\"city\").orderBy(col(\"city_spending\").desc())\n",
        "city_ranked = city_data.withColumn(\"city_rank\", rank().over(city_window))\n",
        "\n",
        "# 3. Identify top 3 customers per city\n",
        "top3_per_city = city_ranked.filter(col(\"city_rank\") <= 3)\n",
        "top3_per_city.show(20)\n",
        "\n",
        "# 4. Identify top 10 customers across all cities\n",
        "top10_customers = ranked_customers.filter(col(\"overall_rank\") <= 10)\n",
        "top10_customers.select(\"customer_id\", \"total_spending\", \"overall_rank\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP39vOxY9RVE",
        "outputId": "0923611d-7f63-46f4-9432-9c914da73928"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+-------------+---------+\n",
            "|customer_id|     city|city_spending|city_rank|\n",
            "+-----------+---------+-------------+---------+\n",
            "|    C011518|bangalore|       332527|        1|\n",
            "|    C024935|bangalore|       315622|        2|\n",
            "|    C025451|bangalore|       303208|        3|\n",
            "|    C028121|  chennai|       340890|        1|\n",
            "|    C027841|  chennai|       287392|        2|\n",
            "|    C030712|  chennai|       284466|        3|\n",
            "|    C016309|    delhi|       325001|        1|\n",
            "|    C022599|    delhi|       314625|        2|\n",
            "|    C018688|    delhi|       306692|        3|\n",
            "|    C032833|hyderabad|       318097|        1|\n",
            "|    C023269|hyderabad|       292791|        2|\n",
            "|    C013263|hyderabad|       291679|        3|\n",
            "|    C032246|  kolkata|       304480|        1|\n",
            "|    C022131|  kolkata|       296888|        2|\n",
            "|    C028450|  kolkata|       296653|        3|\n",
            "|    C048696|   mumbai|       334732|        1|\n",
            "|    C047887|   mumbai|       307401|        2|\n",
            "|    C022721|   mumbai|       306800|        3|\n",
            "|    C002564|     pune|       315172|        1|\n",
            "|    C023148|     pune|       310061|        2|\n",
            "+-----------+---------+-------------+---------+\n",
            "only showing top 20 rows\n",
            "+-----------+--------------+------------+\n",
            "|customer_id|total_spending|overall_rank|\n",
            "+-----------+--------------+------------+\n",
            "|    C043076|        493949|           1|\n",
            "|    C034689|        486879|           2|\n",
            "|    C039985|        484057|           3|\n",
            "|    C026691|        477147|           4|\n",
            "|    C038979|        477138|           5|\n",
            "|    C020762|        474717|           6|\n",
            "|    C044654|        471304|           7|\n",
            "|    C014292|        468617|           8|\n",
            "|    C019565|        467523|           9|\n",
            "|    C045487|        467050|          10|\n",
            "+-----------+--------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 5"
      ],
      "metadata": {
        "id": "ULzFWXzO9fPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loyalty: 3+ different dates AND 2+ different categories\n",
        "loyalty_metrics = clean_orders_df.groupBy(\"customer_id\").agg(\n",
        "    count_distinct(\"order_date_clean\").alias(\"distinct_dates\"),\n",
        "    count_distinct(\"category\").alias(\"distinct_categories_loyalty\")\n",
        ")\n",
        "\n",
        "loyal_customers = loyalty_metrics.withColumn(\"is_loyal\",\n",
        "    when((col(\"distinct_dates\") >= 3) & (col(\"distinct_categories_loyalty\") >= 2), True)\n",
        "    .otherwise(False)\n",
        ")\n",
        "\n",
        "loyal_customers.show(5)\n",
        "\n",
        "# 1. Count loyal customers per city\n",
        "customer_city = clean_orders_df.select(\"customer_id\", \"city\").distinct()\n",
        "loyal_with_city = loyal_customers.join(customer_city, \"customer_id\")\n",
        "loyal_count_per_city = loyal_with_city.groupBy(\"city\", \"is_loyal\").count()\n",
        "loyal_count_per_city.show()\n",
        "\n",
        "# 2. Compare loyal vs non-loyal revenue\n",
        "loyal_revenue = loyal_customers.join(customer_metrics, \"customer_id\") \\\n",
        "    .groupBy(\"is_loyal\").agg(sum(\"total_spending\").alias(\"revenue_contribution\"))\n",
        "loyal_revenue.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r4XOywH9hq2",
        "outputId": "4db5e178-657f-4b70-a855-d25086a996d0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+---------------------------+--------+\n",
            "|customer_id|distinct_dates|distinct_categories_loyalty|is_loyal|\n",
            "+-----------+--------------+---------------------------+--------+\n",
            "|    C009896|             3|                          3|    true|\n",
            "|    C041802|             3|                          4|    true|\n",
            "|    C041216|             3|                          3|    true|\n",
            "|    C030828|             3|                          3|    true|\n",
            "|    C043689|             3|                          4|    true|\n",
            "+-----------+--------------+---------------------------+--------+\n",
            "only showing top 5 rows\n",
            "+---------+--------+-----+\n",
            "|     city|is_loyal|count|\n",
            "+---------+--------+-----+\n",
            "|hyderabad|    true|26748|\n",
            "|     pune|   false|  384|\n",
            "|    delhi|   false|  382|\n",
            "|bangalore|    true|26393|\n",
            "|hyderabad|   false|  424|\n",
            "|    delhi|    true|26635|\n",
            "|   mumbai|   false|  401|\n",
            "|     pune|    true|26601|\n",
            "|  kolkata|   false|  378|\n",
            "|   mumbai|    true|26416|\n",
            "|bangalore|   false|  414|\n",
            "|  chennai|   false|  381|\n",
            "|  kolkata|    true|26448|\n",
            "|  chennai|    true|26562|\n",
            "+---------+--------+-----+\n",
            "\n",
            "+--------+--------------------+\n",
            "|is_loyal|revenue_contribution|\n",
            "+--------+--------------------+\n",
            "|    true|         11185423978|\n",
            "|   false|           150209020|\n",
            "+--------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 6"
      ],
      "metadata": {
        "id": "M6aM7LTB9mEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Compute monthly revenue per city\n",
        "monthly_city_revenue = clean_orders_df.withColumn(\"month\", date_format(col(\"order_date_clean\"), \"yyyy-MM\")) \\\n",
        "    .groupBy(\"month\", \"city\").agg(sum(\"amount\").alias(\"monthly_revenue\"))\n",
        "monthly_city_revenue.orderBy(\"month\", \"city\").show(20)\n",
        "\n",
        "# 2. Compute monthly order count per category\n",
        "monthly_category_orders = clean_orders_df.withColumn(\"month\", date_format(col(\"order_date_clean\"), \"yyyy-MM\")) \\\n",
        "    .groupBy(\"month\", \"category\").agg(count(\"order_id\").alias(\"order_count\"))\n",
        "monthly_category_orders.orderBy(\"month\", \"category\").show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkdTfmj59pAU",
        "outputId": "44724072-6f26-45df-ae7c-b7be96387a15"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------------+\n",
            "|  month|     city|monthly_revenue|\n",
            "+-------+---------+---------------+\n",
            "|2024-01|bangalore|      822339117|\n",
            "|2024-01|  chennai|      818567389|\n",
            "|2024-01|    delhi|      817332633|\n",
            "|2024-01|hyderabad|      833063605|\n",
            "|2024-01|  kolkata|      824920456|\n",
            "|2024-01|   mumbai|      816636150|\n",
            "|2024-01|     pune|      833507124|\n",
            "|2024-02|bangalore|      792163305|\n",
            "|2024-02|  chennai|      796361427|\n",
            "|2024-02|    delhi|      805877007|\n",
            "|2024-02|hyderabad|      796252807|\n",
            "|2024-02|  kolkata|      785096186|\n",
            "|2024-02|   mumbai|      795736235|\n",
            "|2024-02|     pune|      797779557|\n",
            "+-------+---------+---------------+\n",
            "\n",
            "+-------+-----------+-----------+\n",
            "|  month|   category|order_count|\n",
            "+-------+-----------+-----------+\n",
            "|2024-01|electronics|      33063|\n",
            "|2024-01|    fashion|      32509|\n",
            "|2024-01|    grocery|      32986|\n",
            "|2024-01|       home|      33136|\n",
            "|2024-02|electronics|      31889|\n",
            "|2024-02|    fashion|      31810|\n",
            "|2024-02|    grocery|      31761|\n",
            "|2024-02|       home|      31680|\n",
            "+-------+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 7"
      ],
      "metadata": {
        "id": "Erl4dsx79yHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cache reused DataFrames\n",
        "clean_orders_df.cache()\n",
        "customer_metrics.cache()\n",
        "\n",
        "# 2. Use explain(True)\n",
        "print(\"\\n=== Customer Aggregation Explain ===\")\n",
        "customer_metrics.explain(True)\n",
        "\n",
        "print(\"\\n=== Window Ranking Explain ===\")\n",
        "ranked_customers.explain(True)\n",
        "\n",
        "# 3. Check for shuffle stages (look for Exchange in explain output above)\n",
        "\n",
        "# 4. Repartitioning strategy (if needed)\n",
        "# clean_orders_df = clean_orders_df.repartition(\"customer_id\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMnVki-u90JU",
        "outputId": "a1447e14-e343-4b2a-870c-bdd093488e91"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Customer Aggregation Explain ===\n",
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['customer_id], ['customer_id, 'count('order_id) AS total_orders#998, 'sum('amount) AS total_spending#999, 'avg('amount) AS avg_order_value#1000, 'min('order_date_clean) AS first_purchase_date#1001, 'max('order_date_clean) AS last_purchase_date#1002, 'count(distinct 'city) AS distinct_cities#1003, 'count(distinct 'category) AS distinct_categories#1004]\n",
            "+- Filter (((lower(status#873) = completed) AND isnotnull(amount#879)) AND isnotnull(order_date_clean#881))\n",
            "   +- Deduplicate [order_id#866]\n",
            "      +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881]\n",
            "         +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, date_normalized#880, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN to_date(date_normalized#880, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN to_date(date_normalized#880, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date_clean#881]\n",
            "            +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "               +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873]\n",
            "                  +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) ELSE cast(null as int) END AS amount#879, order_date#872, status#873, amount_cleaned#878]\n",
            "                     +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#871, order_date#872, status#873, regexp_replace(amount#871, ,, , 1) AS amount_cleaned#878]\n",
            "                        +- Project [order_id#866, customer_id#867, city#875, category#876, lower(product#870) AS product#877, amount#871, order_date#872, status#873]\n",
            "                           +- Project [order_id#866, customer_id#867, city#875, lower(category#869) AS category#876, product#870, amount#871, order_date#872, status#873]\n",
            "                              +- Project [order_id#866, customer_id#867, lower(city#868) AS city#875, category#869, product#870, amount#871, order_date#872, status#873]\n",
            "                                 +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, trim(city#860, None) AS city#868, trim(category#861, None) AS category#869, trim(product#862, None) AS product#870, trim(amount#863, None) AS amount#871, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873]\n",
            "                                    +- Relation [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "customer_id: string, total_orders: bigint, total_spending: bigint, avg_order_value: double, first_purchase_date: date, last_purchase_date: date, distinct_cities: bigint, distinct_categories: bigint\n",
            "Aggregate [customer_id#867], [customer_id#867, count(order_id#866) AS total_orders#998L, sum(amount#879) AS total_spending#999L, avg(amount#879) AS avg_order_value#1000, min(order_date_clean#881) AS first_purchase_date#1001, max(order_date_clean#881) AS last_purchase_date#1002, count(distinct city#875) AS distinct_cities#1003L, count(distinct category#876) AS distinct_categories#1004L]\n",
            "+- Filter (((lower(status#873) = completed) AND isnotnull(amount#879)) AND isnotnull(order_date_clean#881))\n",
            "   +- Deduplicate [order_id#866]\n",
            "      +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881]\n",
            "         +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, date_normalized#880, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN to_date(date_normalized#880, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN to_date(date_normalized#880, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date_clean#881]\n",
            "            +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "               +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873]\n",
            "                  +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) ELSE cast(null as int) END AS amount#879, order_date#872, status#873, amount_cleaned#878]\n",
            "                     +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#871, order_date#872, status#873, regexp_replace(amount#871, ,, , 1) AS amount_cleaned#878]\n",
            "                        +- Project [order_id#866, customer_id#867, city#875, category#876, lower(product#870) AS product#877, amount#871, order_date#872, status#873]\n",
            "                           +- Project [order_id#866, customer_id#867, city#875, lower(category#869) AS category#876, product#870, amount#871, order_date#872, status#873]\n",
            "                              +- Project [order_id#866, customer_id#867, lower(city#868) AS city#875, category#869, product#870, amount#871, order_date#872, status#873]\n",
            "                                 +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, trim(city#860, None) AS city#868, trim(category#861, None) AS category#869, trim(product#862, None) AS product#870, trim(amount#863, None) AS amount#871, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873]\n",
            "                                    +- Relation [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "InMemoryRelation [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "   +- AdaptiveSparkPlan isFinalPlan=false\n",
            "      +- HashAggregate(keys=[customer_id#867], functions=[first(count(order_id)#2873L, true), first(sum(amount)#2875L, true), first(avg(amount)#2877, true), first(min(order_date_clean)#2879, true), first(max(order_date_clean)#2881, true), count(city#2868), count(category#2869)], output=[customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L])\n",
            "         +- Exchange hashpartitioning(customer_id#867, 200), ENSURE_REQUIREMENTS, [plan_id=4398]\n",
            "            +- HashAggregate(keys=[customer_id#867], functions=[partial_first(count(order_id)#2873L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(sum(amount)#2875L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(avg(amount)#2877, true) FILTER (WHERE (gid#2867 = 0)), partial_first(min(order_date_clean)#2879, true) FILTER (WHERE (gid#2867 = 0)), partial_first(max(order_date_clean)#2881, true) FILTER (WHERE (gid#2867 = 0)), partial_count(city#2868) FILTER (WHERE (gid#2867 = 1)), partial_count(category#2869) FILTER (WHERE (gid#2867 = 2))], output=[customer_id#867, first#2940L, valueSet#2941, first#2942L, valueSet#2943, first#2944, valueSet#2945, first#2946, valueSet#2947, first#2948, valueSet#2949, count#2950L, count#2951L])\n",
            "               +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[count(order_id#2870), sum(amount#2871), avg(amount#2871), min(order_date_clean#2872), max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count(order_id)#2873L, sum(amount)#2875L, avg(amount)#2877, min(order_date_clean)#2879, max(order_date_clean)#2881])\n",
            "                  +- Exchange hashpartitioning(customer_id#867, city#2868, category#2869, gid#2867, 200), ENSURE_REQUIREMENTS, [plan_id=4394]\n",
            "                     +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[partial_count(order_id#2870), partial_sum(amount#2871), partial_avg(amount#2871), partial_min(order_date_clean#2872), partial_max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count#2958L, sum#2959L, sum#2960, count#2961L, min#2962, max#2963])\n",
            "                        +- Expand [[customer_id#867, null, null, 0, order_id#866, amount#879, order_date_clean#881], [customer_id#867, city#875, null, 1, null, null, null], [customer_id#867, null, category#876, 2, null, null, null]], [customer_id#867, city#2868, category#2869, gid#2867, order_id#2870, amount#2871, order_date_clean#2872]\n",
            "                           +- InMemoryTableScan [order_id#866, customer_id#867, city#875, category#876, amount#879, order_date_clean#881]\n",
            "                                 +- InMemoryRelation [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                       +- AdaptiveSparkPlan isFinalPlan=false\n",
            "                                          +- Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                             +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                                +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                   +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4368]\n",
            "                                                      +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                         +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                            +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                               +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                                  +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                                     +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- InMemoryTableScan [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L]\n",
            "      +- InMemoryRelation [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            +- AdaptiveSparkPlan isFinalPlan=false\n",
            "               +- HashAggregate(keys=[customer_id#867], functions=[first(count(order_id)#2873L, true), first(sum(amount)#2875L, true), first(avg(amount)#2877, true), first(min(order_date_clean)#2879, true), first(max(order_date_clean)#2881, true), count(city#2868), count(category#2869)], output=[customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L])\n",
            "                  +- Exchange hashpartitioning(customer_id#867, 200), ENSURE_REQUIREMENTS, [plan_id=4398]\n",
            "                     +- HashAggregate(keys=[customer_id#867], functions=[partial_first(count(order_id)#2873L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(sum(amount)#2875L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(avg(amount)#2877, true) FILTER (WHERE (gid#2867 = 0)), partial_first(min(order_date_clean)#2879, true) FILTER (WHERE (gid#2867 = 0)), partial_first(max(order_date_clean)#2881, true) FILTER (WHERE (gid#2867 = 0)), partial_count(city#2868) FILTER (WHERE (gid#2867 = 1)), partial_count(category#2869) FILTER (WHERE (gid#2867 = 2))], output=[customer_id#867, first#2940L, valueSet#2941, first#2942L, valueSet#2943, first#2944, valueSet#2945, first#2946, valueSet#2947, first#2948, valueSet#2949, count#2950L, count#2951L])\n",
            "                        +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[count(order_id#2870), sum(amount#2871), avg(amount#2871), min(order_date_clean#2872), max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count(order_id)#2873L, sum(amount)#2875L, avg(amount)#2877, min(order_date_clean)#2879, max(order_date_clean)#2881])\n",
            "                           +- Exchange hashpartitioning(customer_id#867, city#2868, category#2869, gid#2867, 200), ENSURE_REQUIREMENTS, [plan_id=4394]\n",
            "                              +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[partial_count(order_id#2870), partial_sum(amount#2871), partial_avg(amount#2871), partial_min(order_date_clean#2872), partial_max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count#2958L, sum#2959L, sum#2960, count#2961L, min#2962, max#2963])\n",
            "                                 +- Expand [[customer_id#867, null, null, 0, order_id#866, amount#879, order_date_clean#881], [customer_id#867, city#875, null, 1, null, null, null], [customer_id#867, null, category#876, 2, null, null, null]], [customer_id#867, city#2868, category#2869, gid#2867, order_id#2870, amount#2871, order_date_clean#2872]\n",
            "                                    +- InMemoryTableScan [order_id#866, customer_id#867, city#875, category#876, amount#879, order_date_clean#881]\n",
            "                                          +- InMemoryRelation [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                                +- AdaptiveSparkPlan isFinalPlan=false\n",
            "                                                   +- Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                                      +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                                         +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                            +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4368]\n",
            "                                                               +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                                  +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                                     +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                                        +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                                           +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                                              +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "\n",
            "\n",
            "=== Window Ranking Explain ===\n",
            "== Parsed Logical Plan ==\n",
            "'Project [unresolvedstarwithcolumns(overall_rank, 'rank() windowspecdefinition('total_spending DESC NULLS LAST, unspecifiedframe$()), None)]\n",
            "+- Project [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L, CASE WHEN ((total_spending#999L >= cast(200000 as bigint)) AND (total_orders#998L >= cast(5 as bigint))) THEN VIP WHEN (total_spending#999L >= cast(100000 as bigint)) THEN Premium ELSE Regular END AS customer_segment#1271]\n",
            "   +- Aggregate [customer_id#867], [customer_id#867, count(order_id#866) AS total_orders#998L, sum(amount#879) AS total_spending#999L, avg(amount#879) AS avg_order_value#1000, min(order_date_clean#881) AS first_purchase_date#1001, max(order_date_clean#881) AS last_purchase_date#1002, count(distinct city#875) AS distinct_cities#1003L, count(distinct category#876) AS distinct_categories#1004L]\n",
            "      +- Filter (((lower(status#873) = completed) AND isnotnull(amount#879)) AND isnotnull(order_date_clean#881))\n",
            "         +- Deduplicate [order_id#866]\n",
            "            +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881]\n",
            "               +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, date_normalized#880, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN to_date(date_normalized#880, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN to_date(date_normalized#880, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date_clean#881]\n",
            "                  +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                     +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873]\n",
            "                        +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) ELSE cast(null as int) END AS amount#879, order_date#872, status#873, amount_cleaned#878]\n",
            "                           +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#871, order_date#872, status#873, regexp_replace(amount#871, ,, , 1) AS amount_cleaned#878]\n",
            "                              +- Project [order_id#866, customer_id#867, city#875, category#876, lower(product#870) AS product#877, amount#871, order_date#872, status#873]\n",
            "                                 +- Project [order_id#866, customer_id#867, city#875, lower(category#869) AS category#876, product#870, amount#871, order_date#872, status#873]\n",
            "                                    +- Project [order_id#866, customer_id#867, lower(city#868) AS city#875, category#869, product#870, amount#871, order_date#872, status#873]\n",
            "                                       +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, trim(city#860, None) AS city#868, trim(category#861, None) AS category#869, trim(product#862, None) AS product#870, trim(amount#863, None) AS amount#871, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873]\n",
            "                                          +- Relation [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "customer_id: string, total_orders: bigint, total_spending: bigint, avg_order_value: double, first_purchase_date: date, last_purchase_date: date, distinct_cities: bigint, distinct_categories: bigint, customer_segment: string, overall_rank: int\n",
            "Project [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L, customer_segment#1271, overall_rank#1628]\n",
            "+- Project [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L, customer_segment#1271, overall_rank#1628, overall_rank#1628]\n",
            "   +- Window [rank(total_spending#999L) windowspecdefinition(total_spending#999L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS overall_rank#1628], [total_spending#999L DESC NULLS LAST]\n",
            "      +- Project [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L, customer_segment#1271]\n",
            "         +- Project [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L, CASE WHEN ((total_spending#999L >= cast(200000 as bigint)) AND (total_orders#998L >= cast(5 as bigint))) THEN VIP WHEN (total_spending#999L >= cast(100000 as bigint)) THEN Premium ELSE Regular END AS customer_segment#1271]\n",
            "            +- Aggregate [customer_id#867], [customer_id#867, count(order_id#866) AS total_orders#998L, sum(amount#879) AS total_spending#999L, avg(amount#879) AS avg_order_value#1000, min(order_date_clean#881) AS first_purchase_date#1001, max(order_date_clean#881) AS last_purchase_date#1002, count(distinct city#875) AS distinct_cities#1003L, count(distinct category#876) AS distinct_categories#1004L]\n",
            "               +- Filter (((lower(status#873) = completed) AND isnotnull(amount#879)) AND isnotnull(order_date_clean#881))\n",
            "                  +- Deduplicate [order_id#866]\n",
            "                     +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881]\n",
            "                        +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, date_normalized#880, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN to_date(date_normalized#880, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN to_date(date_normalized#880, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date_clean#881]\n",
            "                           +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                              +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873]\n",
            "                                 +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) ELSE cast(null as int) END AS amount#879, order_date#872, status#873, amount_cleaned#878]\n",
            "                                    +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#871, order_date#872, status#873, regexp_replace(amount#871, ,, , 1) AS amount_cleaned#878]\n",
            "                                       +- Project [order_id#866, customer_id#867, city#875, category#876, lower(product#870) AS product#877, amount#871, order_date#872, status#873]\n",
            "                                          +- Project [order_id#866, customer_id#867, city#875, lower(category#869) AS category#876, product#870, amount#871, order_date#872, status#873]\n",
            "                                             +- Project [order_id#866, customer_id#867, lower(city#868) AS city#875, category#869, product#870, amount#871, order_date#872, status#873]\n",
            "                                                +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, trim(city#860, None) AS city#868, trim(category#861, None) AS category#869, trim(product#862, None) AS product#870, trim(amount#863, None) AS amount#871, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873]\n",
            "                                                   +- Relation [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Window [rank(total_spending#999L) windowspecdefinition(total_spending#999L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS overall_rank#1628], [total_spending#999L DESC NULLS LAST]\n",
            "+- Project [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L, CASE WHEN ((total_spending#999L >= 200000) AND (total_orders#998L >= 5)) THEN VIP WHEN (total_spending#999L >= 100000) THEN Premium ELSE Regular END AS customer_segment#1271]\n",
            "   +- InMemoryRelation [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "         +- AdaptiveSparkPlan isFinalPlan=false\n",
            "            +- HashAggregate(keys=[customer_id#867], functions=[first(count(order_id)#2873L, true), first(sum(amount)#2875L, true), first(avg(amount)#2877, true), first(min(order_date_clean)#2879, true), first(max(order_date_clean)#2881, true), count(city#2868), count(category#2869)], output=[customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L])\n",
            "               +- Exchange hashpartitioning(customer_id#867, 200), ENSURE_REQUIREMENTS, [plan_id=4398]\n",
            "                  +- HashAggregate(keys=[customer_id#867], functions=[partial_first(count(order_id)#2873L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(sum(amount)#2875L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(avg(amount)#2877, true) FILTER (WHERE (gid#2867 = 0)), partial_first(min(order_date_clean)#2879, true) FILTER (WHERE (gid#2867 = 0)), partial_first(max(order_date_clean)#2881, true) FILTER (WHERE (gid#2867 = 0)), partial_count(city#2868) FILTER (WHERE (gid#2867 = 1)), partial_count(category#2869) FILTER (WHERE (gid#2867 = 2))], output=[customer_id#867, first#2940L, valueSet#2941, first#2942L, valueSet#2943, first#2944, valueSet#2945, first#2946, valueSet#2947, first#2948, valueSet#2949, count#2950L, count#2951L])\n",
            "                     +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[count(order_id#2870), sum(amount#2871), avg(amount#2871), min(order_date_clean#2872), max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count(order_id)#2873L, sum(amount)#2875L, avg(amount)#2877, min(order_date_clean)#2879, max(order_date_clean)#2881])\n",
            "                        +- Exchange hashpartitioning(customer_id#867, city#2868, category#2869, gid#2867, 200), ENSURE_REQUIREMENTS, [plan_id=4394]\n",
            "                           +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[partial_count(order_id#2870), partial_sum(amount#2871), partial_avg(amount#2871), partial_min(order_date_clean#2872), partial_max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count#2958L, sum#2959L, sum#2960, count#2961L, min#2962, max#2963])\n",
            "                              +- Expand [[customer_id#867, null, null, 0, order_id#866, amount#879, order_date_clean#881], [customer_id#867, city#875, null, 1, null, null, null], [customer_id#867, null, category#876, 2, null, null, null]], [customer_id#867, city#2868, category#2869, gid#2867, order_id#2870, amount#2871, order_date_clean#2872]\n",
            "                                 +- InMemoryTableScan [order_id#866, customer_id#867, city#875, category#876, amount#879, order_date_clean#881]\n",
            "                                       +- InMemoryRelation [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                             +- AdaptiveSparkPlan isFinalPlan=false\n",
            "                                                +- Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                                   +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                                      +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                         +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4368]\n",
            "                                                            +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                               +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                                  +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                                     +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                                        +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                                           +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Window [rank(total_spending#999L) windowspecdefinition(total_spending#999L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS overall_rank#1628], [total_spending#999L DESC NULLS LAST]\n",
            "   +- Sort [total_spending#999L DESC NULLS LAST], false, 0\n",
            "      +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=4414]\n",
            "         +- Project [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L, CASE WHEN ((total_spending#999L >= 200000) AND (total_orders#998L >= 5)) THEN VIP WHEN (total_spending#999L >= 100000) THEN Premium ELSE Regular END AS customer_segment#1271]\n",
            "            +- InMemoryTableScan [avg_order_value#1000, customer_id#867, distinct_categories#1004L, distinct_cities#1003L, first_purchase_date#1001, last_purchase_date#1002, total_orders#998L, total_spending#999L]\n",
            "                  +- InMemoryRelation [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                        +- AdaptiveSparkPlan isFinalPlan=false\n",
            "                           +- HashAggregate(keys=[customer_id#867], functions=[first(count(order_id)#2873L, true), first(sum(amount)#2875L, true), first(avg(amount)#2877, true), first(min(order_date_clean)#2879, true), first(max(order_date_clean)#2881, true), count(city#2868), count(category#2869)], output=[customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L])\n",
            "                              +- Exchange hashpartitioning(customer_id#867, 200), ENSURE_REQUIREMENTS, [plan_id=4398]\n",
            "                                 +- HashAggregate(keys=[customer_id#867], functions=[partial_first(count(order_id)#2873L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(sum(amount)#2875L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(avg(amount)#2877, true) FILTER (WHERE (gid#2867 = 0)), partial_first(min(order_date_clean)#2879, true) FILTER (WHERE (gid#2867 = 0)), partial_first(max(order_date_clean)#2881, true) FILTER (WHERE (gid#2867 = 0)), partial_count(city#2868) FILTER (WHERE (gid#2867 = 1)), partial_count(category#2869) FILTER (WHERE (gid#2867 = 2))], output=[customer_id#867, first#2940L, valueSet#2941, first#2942L, valueSet#2943, first#2944, valueSet#2945, first#2946, valueSet#2947, first#2948, valueSet#2949, count#2950L, count#2951L])\n",
            "                                    +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[count(order_id#2870), sum(amount#2871), avg(amount#2871), min(order_date_clean#2872), max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count(order_id)#2873L, sum(amount)#2875L, avg(amount)#2877, min(order_date_clean)#2879, max(order_date_clean)#2881])\n",
            "                                       +- Exchange hashpartitioning(customer_id#867, city#2868, category#2869, gid#2867, 200), ENSURE_REQUIREMENTS, [plan_id=4394]\n",
            "                                          +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[partial_count(order_id#2870), partial_sum(amount#2871), partial_avg(amount#2871), partial_min(order_date_clean#2872), partial_max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count#2958L, sum#2959L, sum#2960, count#2961L, min#2962, max#2963])\n",
            "                                             +- Expand [[customer_id#867, null, null, 0, order_id#866, amount#879, order_date_clean#881], [customer_id#867, city#875, null, 1, null, null, null], [customer_id#867, null, category#876, 2, null, null, null]], [customer_id#867, city#2868, category#2869, gid#2867, order_id#2870, amount#2871, order_date_clean#2872]\n",
            "                                                +- InMemoryTableScan [order_id#866, customer_id#867, city#875, category#876, amount#879, order_date_clean#881]\n",
            "                                                      +- InMemoryRelation [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                                            +- AdaptiveSparkPlan isFinalPlan=false\n",
            "                                                               +- Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                                                  +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                                                     +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                                        +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4368]\n",
            "                                                                           +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                                              +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                                                 +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                                                    +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                                                       +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                                                          +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 8"
      ],
      "metadata": {
        "id": "b49qD0D7-CSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create segment lookup\n",
        "segment_lookup_data = [\n",
        "    (\"VIP\", 1),\n",
        "    (\"Premium\", 2),\n",
        "    (\"Regular\", 3)\n",
        "]\n",
        "segment_lookup_df = spark.createDataFrame(segment_lookup_data, [\"segment_label\", \"segment_code\"])\n",
        "\n",
        "# Join with broadcast\n",
        "from pyspark.sql.functions import broadcast\n",
        "customer_with_code = customer_segments.join(\n",
        "    broadcast(segment_lookup_df),\n",
        "    customer_segments.customer_segment == segment_lookup_df.segment_label\n",
        ")\n",
        "\n",
        "customer_with_code.show(5)\n",
        "\n",
        "# Verify BroadcastHashJoin in plan\n",
        "print(\"\\n=== Broadcast Join Explain ===\")\n",
        "customer_with_code.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9sMpVd7-E6O",
        "outputId": "1401449e-de04-47d3-b154-e4f2a34b752a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+--------------+---------------+-------------------+------------------+---------------+-------------------+----------------+-------------+------------+\n",
            "|customer_id|total_orders|total_spending|avg_order_value|first_purchase_date|last_purchase_date|distinct_cities|distinct_categories|customer_segment|segment_label|segment_code|\n",
            "+-----------+------------+--------------+---------------+-------------------+------------------+---------------+-------------------+----------------+-------------+------------+\n",
            "|    C016502|           6|        318813|        53135.5|         2024-01-03|        2024-02-12|              3|                  3|             VIP|          VIP|           1|\n",
            "|    C036542|           5|        232053|        46410.6|         2024-01-03|        2024-02-12|              3|                  4|             VIP|          VIP|           1|\n",
            "|    C041216|           5|        268589|        53717.8|         2024-01-17|        2024-02-26|              4|                  3|             VIP|          VIP|           1|\n",
            "|    C007013|           5|        241427|        48285.4|         2024-01-14|        2024-02-23|              2|                  2|             VIP|          VIP|           1|\n",
            "|    C030046|           6|        276423|        46070.5|         2024-01-07|        2024-02-16|              5|                  4|             VIP|          VIP|           1|\n",
            "+-----------+------------+--------------+---------------+-------------------+------------------+---------------+-------------------+----------------+-------------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "=== Broadcast Join Explain ===\n",
            "== Parsed Logical Plan ==\n",
            "Join Inner, (customer_segment#1271 = segment_label#3250)\n",
            ":- Project [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L, CASE WHEN ((total_spending#999L >= cast(200000 as bigint)) AND (total_orders#998L >= cast(5 as bigint))) THEN VIP WHEN (total_spending#999L >= cast(100000 as bigint)) THEN Premium ELSE Regular END AS customer_segment#1271]\n",
            ":  +- Aggregate [customer_id#867], [customer_id#867, count(order_id#866) AS total_orders#998L, sum(amount#879) AS total_spending#999L, avg(amount#879) AS avg_order_value#1000, min(order_date_clean#881) AS first_purchase_date#1001, max(order_date_clean#881) AS last_purchase_date#1002, count(distinct city#875) AS distinct_cities#1003L, count(distinct category#876) AS distinct_categories#1004L]\n",
            ":     +- Filter (((lower(status#873) = completed) AND isnotnull(amount#879)) AND isnotnull(order_date_clean#881))\n",
            ":        +- Deduplicate [order_id#866]\n",
            ":           +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881]\n",
            ":              +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, date_normalized#880, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN to_date(date_normalized#880, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN to_date(date_normalized#880, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date_clean#881]\n",
            ":                 +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            ":                    +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873]\n",
            ":                       +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) ELSE cast(null as int) END AS amount#879, order_date#872, status#873, amount_cleaned#878]\n",
            ":                          +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#871, order_date#872, status#873, regexp_replace(amount#871, ,, , 1) AS amount_cleaned#878]\n",
            ":                             +- Project [order_id#866, customer_id#867, city#875, category#876, lower(product#870) AS product#877, amount#871, order_date#872, status#873]\n",
            ":                                +- Project [order_id#866, customer_id#867, city#875, lower(category#869) AS category#876, product#870, amount#871, order_date#872, status#873]\n",
            ":                                   +- Project [order_id#866, customer_id#867, lower(city#868) AS city#875, category#869, product#870, amount#871, order_date#872, status#873]\n",
            ":                                      +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, trim(city#860, None) AS city#868, trim(category#861, None) AS category#869, trim(product#862, None) AS product#870, trim(amount#863, None) AS amount#871, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873]\n",
            ":                                         +- Relation [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] csv\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- LogicalRDD [segment_label#3250, segment_code#3251L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "customer_id: string, total_orders: bigint, total_spending: bigint, avg_order_value: double, first_purchase_date: date, last_purchase_date: date, distinct_cities: bigint, distinct_categories: bigint, customer_segment: string, segment_label: string, segment_code: bigint\n",
            "Join Inner, (customer_segment#1271 = segment_label#3250)\n",
            ":- Project [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L, CASE WHEN ((total_spending#999L >= cast(200000 as bigint)) AND (total_orders#998L >= cast(5 as bigint))) THEN VIP WHEN (total_spending#999L >= cast(100000 as bigint)) THEN Premium ELSE Regular END AS customer_segment#1271]\n",
            ":  +- Aggregate [customer_id#867], [customer_id#867, count(order_id#866) AS total_orders#998L, sum(amount#879) AS total_spending#999L, avg(amount#879) AS avg_order_value#1000, min(order_date_clean#881) AS first_purchase_date#1001, max(order_date_clean#881) AS last_purchase_date#1002, count(distinct city#875) AS distinct_cities#1003L, count(distinct category#876) AS distinct_categories#1004L]\n",
            ":     +- Filter (((lower(status#873) = completed) AND isnotnull(amount#879)) AND isnotnull(order_date_clean#881))\n",
            ":        +- Deduplicate [order_id#866]\n",
            ":           +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881]\n",
            ":              +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, date_normalized#880, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN to_date(date_normalized#880, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN to_date(date_normalized#880, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date_clean#881]\n",
            ":                 +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            ":                    +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873]\n",
            ":                       +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) ELSE cast(null as int) END AS amount#879, order_date#872, status#873, amount_cleaned#878]\n",
            ":                          +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#871, order_date#872, status#873, regexp_replace(amount#871, ,, , 1) AS amount_cleaned#878]\n",
            ":                             +- Project [order_id#866, customer_id#867, city#875, category#876, lower(product#870) AS product#877, amount#871, order_date#872, status#873]\n",
            ":                                +- Project [order_id#866, customer_id#867, city#875, lower(category#869) AS category#876, product#870, amount#871, order_date#872, status#873]\n",
            ":                                   +- Project [order_id#866, customer_id#867, lower(city#868) AS city#875, category#869, product#870, amount#871, order_date#872, status#873]\n",
            ":                                      +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, trim(city#860, None) AS city#868, trim(category#861, None) AS category#869, trim(product#862, None) AS product#870, trim(amount#863, None) AS amount#871, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873]\n",
            ":                                         +- Relation [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] csv\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- LogicalRDD [segment_label#3250, segment_code#3251L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Join Inner, (customer_segment#1271 = segment_label#3250), rightHint=(strategy=broadcast)\n",
            ":- Project [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L, CASE WHEN ((total_spending#999L >= 200000) AND (total_orders#998L >= 5)) THEN VIP WHEN (total_spending#999L >= 100000) THEN Premium ELSE Regular END AS customer_segment#1271]\n",
            ":  +- InMemoryRelation [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            ":        +- AdaptiveSparkPlan isFinalPlan=true\n",
            "            +- == Final Plan ==\n",
            "               ResultQueryStage 3\n",
            "               +- *(3) HashAggregate(keys=[customer_id#867], functions=[first(count(order_id)#2873L, true), first(sum(amount)#2875L, true), first(avg(amount)#2877, true), first(min(order_date_clean)#2879, true), first(max(order_date_clean)#2881, true), count(city#2868), count(category#2869)], output=[customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L])\n",
            "                  +- ShuffleQueryStage 2\n",
            "                     +- Exchange hashpartitioning(customer_id#867, 200), ENSURE_REQUIREMENTS, [plan_id=4604]\n",
            "                        +- *(2) HashAggregate(keys=[customer_id#867], functions=[partial_first(count(order_id)#2873L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(sum(amount)#2875L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(avg(amount)#2877, true) FILTER (WHERE (gid#2867 = 0)), partial_first(min(order_date_clean)#2879, true) FILTER (WHERE (gid#2867 = 0)), partial_first(max(order_date_clean)#2881, true) FILTER (WHERE (gid#2867 = 0)), partial_count(city#2868) FILTER (WHERE (gid#2867 = 1)), partial_count(category#2869) FILTER (WHERE (gid#2867 = 2))], output=[customer_id#867, first#2940L, valueSet#2941, first#2942L, valueSet#2943, first#2944, valueSet#2945, first#2946, valueSet#2947, first#2948, valueSet#2949, count#2950L, count#2951L])\n",
            "                           +- *(2) HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[count(order_id#2870), sum(amount#2871), avg(amount#2871), min(order_date_clean#2872), max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count(order_id)#2873L, sum(amount)#2875L, avg(amount)#2877, min(order_date_clean)#2879, max(order_date_clean)#2881])\n",
            "                              +- AQEShuffleRead coalesced\n",
            "                                 +- ShuffleQueryStage 1\n",
            "                                    +- Exchange hashpartitioning(customer_id#867, city#2868, category#2869, gid#2867, 200), ENSURE_REQUIREMENTS, [plan_id=4569]\n",
            "                                       +- *(1) HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[partial_count(order_id#2870), partial_sum(amount#2871), partial_avg(amount#2871), partial_min(order_date_clean#2872), partial_max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count#2958L, sum#2959L, sum#2960, count#2961L, min#2962, max#2963])\n",
            "                                          +- *(1) Expand [[customer_id#867, null, null, 0, order_id#866, amount#879, order_date_clean#881], [customer_id#867, city#875, null, 1, null, null, null], [customer_id#867, null, category#876, 2, null, null, null]], [customer_id#867, city#2868, category#2869, gid#2867, order_id#2870, amount#2871, order_date_clean#2872]\n",
            "                                             +- TableCacheQueryStage 0\n",
            "                                                +- InMemoryTableScan [order_id#866, customer_id#867, city#875, category#876, amount#879, order_date_clean#881]\n",
            "                                                      +- InMemoryRelation [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                                            +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                                                +- == Final Plan ==\n",
            "                                                   ResultQueryStage 1\n",
            "                                                   +- *(3) Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                                      +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                                         +- *(2) Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                            +- ShuffleQueryStage 0\n",
            "                                                               +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4502]\n",
            "                                                                  +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                                     +- *(1) Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                                        +- *(1) Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                                           +- *(1) Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                                              +- *(1) Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                                                 +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "                                                +- == Initial Plan ==\n",
            "                                                   Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                                   +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                                      +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                         +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4368]\n",
            "                                                            +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                               +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                                  +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                                     +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                                        +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                                           +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "            +- == Initial Plan ==\n",
            "               HashAggregate(keys=[customer_id#867], functions=[first(count(order_id)#2873L, true), first(sum(amount)#2875L, true), first(avg(amount)#2877, true), first(min(order_date_clean)#2879, true), first(max(order_date_clean)#2881, true), count(city#2868), count(category#2869)], output=[customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L])\n",
            "               +- Exchange hashpartitioning(customer_id#867, 200), ENSURE_REQUIREMENTS, [plan_id=4398]\n",
            "                  +- HashAggregate(keys=[customer_id#867], functions=[partial_first(count(order_id)#2873L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(sum(amount)#2875L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(avg(amount)#2877, true) FILTER (WHERE (gid#2867 = 0)), partial_first(min(order_date_clean)#2879, true) FILTER (WHERE (gid#2867 = 0)), partial_first(max(order_date_clean)#2881, true) FILTER (WHERE (gid#2867 = 0)), partial_count(city#2868) FILTER (WHERE (gid#2867 = 1)), partial_count(category#2869) FILTER (WHERE (gid#2867 = 2))], output=[customer_id#867, first#2940L, valueSet#2941, first#2942L, valueSet#2943, first#2944, valueSet#2945, first#2946, valueSet#2947, first#2948, valueSet#2949, count#2950L, count#2951L])\n",
            "                     +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[count(order_id#2870), sum(amount#2871), avg(amount#2871), min(order_date_clean#2872), max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count(order_id)#2873L, sum(amount)#2875L, avg(amount)#2877, min(order_date_clean)#2879, max(order_date_clean)#2881])\n",
            "                        +- Exchange hashpartitioning(customer_id#867, city#2868, category#2869, gid#2867, 200), ENSURE_REQUIREMENTS, [plan_id=4394]\n",
            "                           +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[partial_count(order_id#2870), partial_sum(amount#2871), partial_avg(amount#2871), partial_min(order_date_clean#2872), partial_max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count#2958L, sum#2959L, sum#2960, count#2961L, min#2962, max#2963])\n",
            "                              +- Expand [[customer_id#867, null, null, 0, order_id#866, amount#879, order_date_clean#881], [customer_id#867, city#875, null, 1, null, null, null], [customer_id#867, null, category#876, 2, null, null, null]], [customer_id#867, city#2868, category#2869, gid#2867, order_id#2870, amount#2871, order_date_clean#2872]\n",
            "                                 +- InMemoryTableScan [order_id#866, customer_id#867, city#875, category#876, amount#879, order_date_clean#881]\n",
            "                                       +- InMemoryRelation [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                             +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                                 +- == Final Plan ==\n",
            "                                    ResultQueryStage 1\n",
            "                                    +- *(3) Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                       +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                          +- *(2) Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                             +- ShuffleQueryStage 0\n",
            "                                                +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4502]\n",
            "                                                   +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                      +- *(1) Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                         +- *(1) Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                            +- *(1) Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                               +- *(1) Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                                  +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "                                 +- == Initial Plan ==\n",
            "                                    Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                    +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                       +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                          +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4368]\n",
            "                                             +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                   +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                      +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                         +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                            +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "+- Filter isnotnull(segment_label#3250)\n",
            "   +- LogicalRDD [segment_label#3250, segment_code#3251L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- BroadcastHashJoin [customer_segment#1271], [segment_label#3250], Inner, BuildRight, false\n",
            "   :- Project [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L, CASE WHEN ((total_spending#999L >= 200000) AND (total_orders#998L >= 5)) THEN VIP WHEN (total_spending#999L >= 100000) THEN Premium ELSE Regular END AS customer_segment#1271]\n",
            "   :  +- InMemoryTableScan [avg_order_value#1000, customer_id#867, distinct_categories#1004L, distinct_cities#1003L, first_purchase_date#1001, last_purchase_date#1002, total_orders#998L, total_spending#999L]\n",
            "   :        +- InMemoryRelation [customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "   :              +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                     +- == Final Plan ==\n",
            "                        ResultQueryStage 3\n",
            "                        +- *(3) HashAggregate(keys=[customer_id#867], functions=[first(count(order_id)#2873L, true), first(sum(amount)#2875L, true), first(avg(amount)#2877, true), first(min(order_date_clean)#2879, true), first(max(order_date_clean)#2881, true), count(city#2868), count(category#2869)], output=[customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L])\n",
            "                           +- ShuffleQueryStage 2\n",
            "                              +- Exchange hashpartitioning(customer_id#867, 200), ENSURE_REQUIREMENTS, [plan_id=4604]\n",
            "                                 +- *(2) HashAggregate(keys=[customer_id#867], functions=[partial_first(count(order_id)#2873L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(sum(amount)#2875L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(avg(amount)#2877, true) FILTER (WHERE (gid#2867 = 0)), partial_first(min(order_date_clean)#2879, true) FILTER (WHERE (gid#2867 = 0)), partial_first(max(order_date_clean)#2881, true) FILTER (WHERE (gid#2867 = 0)), partial_count(city#2868) FILTER (WHERE (gid#2867 = 1)), partial_count(category#2869) FILTER (WHERE (gid#2867 = 2))], output=[customer_id#867, first#2940L, valueSet#2941, first#2942L, valueSet#2943, first#2944, valueSet#2945, first#2946, valueSet#2947, first#2948, valueSet#2949, count#2950L, count#2951L])\n",
            "                                    +- *(2) HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[count(order_id#2870), sum(amount#2871), avg(amount#2871), min(order_date_clean#2872), max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count(order_id)#2873L, sum(amount)#2875L, avg(amount)#2877, min(order_date_clean)#2879, max(order_date_clean)#2881])\n",
            "                                       +- AQEShuffleRead coalesced\n",
            "                                          +- ShuffleQueryStage 1\n",
            "                                             +- Exchange hashpartitioning(customer_id#867, city#2868, category#2869, gid#2867, 200), ENSURE_REQUIREMENTS, [plan_id=4569]\n",
            "                                                +- *(1) HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[partial_count(order_id#2870), partial_sum(amount#2871), partial_avg(amount#2871), partial_min(order_date_clean#2872), partial_max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count#2958L, sum#2959L, sum#2960, count#2961L, min#2962, max#2963])\n",
            "                                                   +- *(1) Expand [[customer_id#867, null, null, 0, order_id#866, amount#879, order_date_clean#881], [customer_id#867, city#875, null, 1, null, null, null], [customer_id#867, null, category#876, 2, null, null, null]], [customer_id#867, city#2868, category#2869, gid#2867, order_id#2870, amount#2871, order_date_clean#2872]\n",
            "                                                      +- TableCacheQueryStage 0\n",
            "                                                         +- InMemoryTableScan [order_id#866, customer_id#867, city#875, category#876, amount#879, order_date_clean#881]\n",
            "                                                               +- InMemoryRelation [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                                                     +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                                                +- == Final Plan ==\n",
            "                                                   ResultQueryStage 1\n",
            "                                                   +- *(3) Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                                      +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                                         +- *(2) Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                            +- ShuffleQueryStage 0\n",
            "                                                               +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4502]\n",
            "                                                                  +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                                     +- *(1) Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                                        +- *(1) Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                                           +- *(1) Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                                              +- *(1) Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                                                 +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "                                                +- == Initial Plan ==\n",
            "                                                   Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                                   +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                                      +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                         +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4368]\n",
            "                                                            +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                               +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                                  +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                                     +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                                        +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                                           +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "                     +- == Initial Plan ==\n",
            "                        HashAggregate(keys=[customer_id#867], functions=[first(count(order_id)#2873L, true), first(sum(amount)#2875L, true), first(avg(amount)#2877, true), first(min(order_date_clean)#2879, true), first(max(order_date_clean)#2881, true), count(city#2868), count(category#2869)], output=[customer_id#867, total_orders#998L, total_spending#999L, avg_order_value#1000, first_purchase_date#1001, last_purchase_date#1002, distinct_cities#1003L, distinct_categories#1004L])\n",
            "                        +- Exchange hashpartitioning(customer_id#867, 200), ENSURE_REQUIREMENTS, [plan_id=4398]\n",
            "                           +- HashAggregate(keys=[customer_id#867], functions=[partial_first(count(order_id)#2873L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(sum(amount)#2875L, true) FILTER (WHERE (gid#2867 = 0)), partial_first(avg(amount)#2877, true) FILTER (WHERE (gid#2867 = 0)), partial_first(min(order_date_clean)#2879, true) FILTER (WHERE (gid#2867 = 0)), partial_first(max(order_date_clean)#2881, true) FILTER (WHERE (gid#2867 = 0)), partial_count(city#2868) FILTER (WHERE (gid#2867 = 1)), partial_count(category#2869) FILTER (WHERE (gid#2867 = 2))], output=[customer_id#867, first#2940L, valueSet#2941, first#2942L, valueSet#2943, first#2944, valueSet#2945, first#2946, valueSet#2947, first#2948, valueSet#2949, count#2950L, count#2951L])\n",
            "                              +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[count(order_id#2870), sum(amount#2871), avg(amount#2871), min(order_date_clean#2872), max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count(order_id)#2873L, sum(amount)#2875L, avg(amount)#2877, min(order_date_clean)#2879, max(order_date_clean)#2881])\n",
            "                                 +- Exchange hashpartitioning(customer_id#867, city#2868, category#2869, gid#2867, 200), ENSURE_REQUIREMENTS, [plan_id=4394]\n",
            "                                    +- HashAggregate(keys=[customer_id#867, city#2868, category#2869, gid#2867], functions=[partial_count(order_id#2870), partial_sum(amount#2871), partial_avg(amount#2871), partial_min(order_date_clean#2872), partial_max(order_date_clean#2872)], output=[customer_id#867, city#2868, category#2869, gid#2867, count#2958L, sum#2959L, sum#2960, count#2961L, min#2962, max#2963])\n",
            "                                       +- Expand [[customer_id#867, null, null, 0, order_id#866, amount#879, order_date_clean#881], [customer_id#867, city#875, null, 1, null, null, null], [customer_id#867, null, category#876, 2, null, null, null]], [customer_id#867, city#2868, category#2869, gid#2867, order_id#2870, amount#2871, order_date_clean#2872]\n",
            "                                          +- InMemoryTableScan [order_id#866, customer_id#867, city#875, category#876, amount#879, order_date_clean#881]\n",
            "                                                +- InMemoryRelation [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, order_date_clean#881], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                                      +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                                 +- == Final Plan ==\n",
            "                                    ResultQueryStage 1\n",
            "                                    +- *(3) Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                       +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                          +- *(2) Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                             +- ShuffleQueryStage 0\n",
            "                                                +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4502]\n",
            "                                                   +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                      +- *(1) Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                         +- *(1) Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                            +- *(1) Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                               +- *(1) Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                                  +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "                                 +- == Initial Plan ==\n",
            "                                    Filter (isnotnull(status#2697) AND (((lower(status#2697) = completed) AND isnotnull(amount#2693)) AND isnotnull(order_date_clean#2699)))\n",
            "                                    +- SortAggregate(key=[order_id#866], functions=[first(customer_id#867, false), first(city#875, false), first(category#876, false), first(product#877, false), first(amount#879, false), first(order_date#872, false), first(status#873, false), first(order_date_clean#881, false)], output=[order_id#866, customer_id#2685, city#2687, category#2689, product#2691, amount#2693, order_date#2695, status#2697, order_date_clean#2699])\n",
            "                                       +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                          +- Exchange hashpartitioning(order_id#866, 200), ENSURE_REQUIREMENTS, [plan_id=4368]\n",
            "                                             +- SortAggregate(key=[order_id#866], functions=[partial_first(customer_id#867, false), partial_first(city#875, false), partial_first(category#876, false), partial_first(product#877, false), partial_first(amount#879, false), partial_first(order_date#872, false), partial_first(status#873, false), partial_first(order_date_clean#881, false)], output=[order_id#866, first#2716, valueSet#2717, first#2718, valueSet#2719, first#2720, valueSet#2721, first#2722, valueSet#2723, first#2724, valueSet#2725, first#2726, valueSet#2727, first#2728, valueSet#2729, first#2730, valueSet#2731])\n",
            "                                                +- Sort [order_id#866 ASC NULLS FIRST], false, 0\n",
            "                                                   +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, amount#879, order_date#872, status#873, CASE WHEN RLIKE(date_normalized#880, ^[0-9]{4}-[0-9]{2}-[0-9]{2}$) THEN cast(gettimestamp(date_normalized#880, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(date_normalized#880, ^[0-9]{2}-[0-9]{2}-[0-9]{4}$) THEN cast(gettimestamp(date_normalized#880, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date_clean#881]\n",
            "                                                      +- Project [order_id#866, customer_id#867, city#875, category#876, product#877, CASE WHEN RLIKE(amount_cleaned#878, ^-?[0-9]+$) THEN cast(amount_cleaned#878 as int) END AS amount#879, order_date#872, status#873, regexp_replace(order_date#872, /, -, 1) AS date_normalized#880]\n",
            "                                                         +- Project [trim(order_id#858, None) AS order_id#866, trim(customer_id#859, None) AS customer_id#867, lower(trim(city#860, None)) AS city#875, lower(trim(category#861, None)) AS category#876, lower(trim(product#862, None)) AS product#877, trim(order_date#864, None) AS order_date#872, trim(status#865, None) AS status#873, regexp_replace(trim(amount#863, None), ,, , 1) AS amount_cleaned#878]\n",
            "                                                            +- FileScan csv [order_id#858,customer_id#859,city#860,category#861,product#862,amount#863,order_date#864,status#865] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=4669]\n",
            "      +- Filter isnotnull(segment_label#3250)\n",
            "         +- Scan ExistingRDD[segment_label#3250,segment_code#3251L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 9"
      ],
      "metadata": {
        "id": "YVzsh5jb-Jz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sort customers\n",
        "sorted_customers = customer_segments.orderBy(\n",
        "    col(\"total_spending\").desc(),\n",
        "    col(\"total_orders\").desc()\n",
        ")\n",
        "sorted_customers.show(10)\n",
        "\n",
        "# 2. Create two sets\n",
        "electronics_customers = clean_orders_df.filter(col(\"category\") == \"electronics\") \\\n",
        "    .select(\"customer_id\").distinct()\n",
        "\n",
        "grocery_customers = clean_orders_df.filter(col(\"category\") == \"grocery\") \\\n",
        "    .select(\"customer_id\").distinct()\n",
        "\n",
        "# 3. Find customers in both sets (intersection)\n",
        "both_sets = electronics_customers.intersect(grocery_customers)\n",
        "print(f\"Customers in both Electronics and Grocery: {both_sets.count()}\")\n",
        "\n",
        "# Customers in only one set\n",
        "only_electronics = electronics_customers.subtract(grocery_customers)\n",
        "only_grocery = grocery_customers.subtract(electronics_customers)\n",
        "print(f\"Only Electronics: {only_electronics.count()}\")\n",
        "print(f\"Only Grocery: {only_grocery.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1Gs1WZJ-Lvw",
        "outputId": "1ff262ad-1f88-4bc6-9601-5078b98a1161"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+--------------+-----------------+-------------------+------------------+---------------+-------------------+----------------+\n",
            "|customer_id|total_orders|total_spending|  avg_order_value|first_purchase_date|last_purchase_date|distinct_cities|distinct_categories|customer_segment|\n",
            "+-----------+------------+--------------+-----------------+-------------------+------------------+---------------+-------------------+----------------+\n",
            "|    C043076|           6|        493949|82324.83333333333|         2024-01-17|        2024-02-26|              5|                  4|             VIP|\n",
            "|    C034689|           6|        486879|          81146.5|         2024-01-10|        2024-02-19|              4|                  3|             VIP|\n",
            "|    C039985|           6|        484057|80676.16666666667|         2024-01-06|        2024-02-15|              3|                  4|             VIP|\n",
            "|    C026691|           6|        477147|          79524.5|         2024-01-12|        2024-02-21|              4|                  3|             VIP|\n",
            "|    C038979|           6|        477138|          79523.0|         2024-01-20|        2024-02-29|              5|                  4|             VIP|\n",
            "|    C020762|           6|        474717|          79119.5|         2024-01-03|        2024-02-12|              5|                  3|             VIP|\n",
            "|    C044654|           6|        471304|78550.66666666667|         2024-01-15|        2024-02-24|              5|                  2|             VIP|\n",
            "|    C014292|           6|        468617|78102.83333333333|         2024-01-13|        2024-02-22|              5|                  3|             VIP|\n",
            "|    C019565|           6|        467523|          77920.5|         2024-01-06|        2024-02-15|              3|                  3|             VIP|\n",
            "|    C045487|           6|        467050|77841.66666666667|         2024-01-08|        2024-02-17|              4|                  3|             VIP|\n",
            "+-----------+------------+--------------+-----------------+-------------------+------------------+---------------+-------------------+----------------+\n",
            "only showing top 10 rows\n",
            "Customers in both Electronics and Grocery: 28520\n",
            "Only Electronics: 8906\n",
            "Only Grocery: 8867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 10"
      ],
      "metadata": {
        "id": "-wPz90Dx-U_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Write customer master dataset to Parquet, partitioned by customer_segment\n",
        "customer_segments.write.mode(\"overwrite\") \\\n",
        "    .partitionBy(\"customer_segment\") \\\n",
        "    .parquet(\"customer_master.parquet\")\n",
        "\n",
        "# 2. Write monthly analytics to ORC\n",
        "monthly_city_revenue.write.mode(\"overwrite\").orc(\"monthly_analytics.orc\")\n",
        "\n",
        "# 3. Read back and validate\n",
        "customer_master_read = spark.read.parquet(\"customer_master.parquet\")\n",
        "customer_master_read.show(5)\n",
        "\n",
        "monthly_analytics_read = spark.read.orc(\"monthly_analytics.orc\")\n",
        "monthly_analytics_read.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is600hYD-Wrz",
        "outputId": "1062f8bc-990c-48d8-958b-83c1e8c563ef"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+--------------+------------------+-------------------+------------------+---------------+-------------------+----------------+\n",
            "|customer_id|total_orders|total_spending|   avg_order_value|first_purchase_date|last_purchase_date|distinct_cities|distinct_categories|customer_segment|\n",
            "+-----------+------------+--------------+------------------+-------------------+------------------+---------------+-------------------+----------------+\n",
            "|    C014073|           5|        252076|           50415.2|         2024-01-14|        2024-02-23|              5|                  3|             VIP|\n",
            "|    C002702|           6|        298831|49805.166666666664|         2024-01-03|        2024-02-12|              4|                  3|             VIP|\n",
            "|    C002365|           6|        360985|60164.166666666664|         2024-01-06|        2024-02-15|              4|                  3|             VIP|\n",
            "|    C030068|           6|        221767|36961.166666666664|         2024-01-09|        2024-02-18|              5|                  3|             VIP|\n",
            "|    C004866|           5|        263377|           52675.4|         2024-01-07|        2024-02-16|              3|                  3|             VIP|\n",
            "+-----------+------------+--------------+------------------+-------------------+------------------+---------------+-------------------+----------------+\n",
            "only showing top 5 rows\n",
            "+-------+---------+---------------+\n",
            "|  month|     city|monthly_revenue|\n",
            "+-------+---------+---------------+\n",
            "|2024-01|  kolkata|      824920456|\n",
            "|2024-02|hyderabad|      796252807|\n",
            "|2024-01|  chennai|      818567389|\n",
            "|2024-02|bangalore|      792163305|\n",
            "|2024-01|hyderabad|      833063605|\n",
            "+-------+---------+---------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PHASE 11"
      ],
      "metadata": {
        "id": "sepd3924-btZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DANGEROUS CODE:\n",
        "df = df.groupBy(\"customer_id\").sum(\"amount\").show()\n",
        "\n",
        "EXPLANATION:\n",
        "1. What df becomes:\n",
        "   - The groupBy().sum() returns a DataFrame with aggregated results\n",
        "   - But .show() returns None (it doesn't return a DataFrame)\n",
        "   - So df is reassigned to None\n",
        "\n",
        "2. Why pipeline breaks:\n",
        "   - After this line, df is None, not a DataFrame\n",
        "   - Any subsequent operation on df will fail with AttributeError\n",
        "   - The original df is lost\n",
        "\n",
        "CORRECT APPROACH:\n",
        "result_df = df.groupBy(\"customer_id\").sum(\"amount\")\n",
        "result_df.show()\n",
        "\n",
        "Or use agg() for clarity:\n",
        "result_df = df.groupBy(\"customer_id\").agg(sum(\"amount\").alias(\"total_amount\"))\n",
        "result_df.show()"
      ],
      "metadata": {
        "id": "kWDq4Awb-in5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "HiFBL54h-dZK"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}