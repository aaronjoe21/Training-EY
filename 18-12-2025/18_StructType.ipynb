{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#StructType"
      ],
      "metadata": {
        "id": "sd73fDIY2Fg_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiS6l4WxoO29"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Struct_Type\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "from pyspark.sql.types import (\n",
        "    StructType, StructField,\n",
        "    StringType, IntegerType, LongType\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = [\n",
        "    (\"U001\",\"Abhishek\",28,\"Hyderabad\",50000),\n",
        "    (\"U002\",\"Neha\",32,\"Delhi\",62000),\n",
        "    (\"U003\",\"Ravi\",25,\"Bangalore\",45000),\n",
        "    (\"U004\",\"Pooja\",29,\"Mumbai\",58000)\n",
        "]"
      ],
      "metadata": {
        "id": "MDhautfro9Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_schema = StructType ([\n",
        "    StructField(\"user_id\", StringType(), nullable=False),\n",
        "    StructField(\"name\", StringType(), nullable=True),\n",
        "    StructField(\"age\", IntegerType(), nullable=True),\n",
        "    StructField(\"city\", StringType(), nullable=True),\n",
        "    StructField(\"salary\", LongType(), nullable=True),\n",
        "])"
      ],
      "metadata": {
        "id": "6rLncAZSpQll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_users= spark.createDataFrame(raw_data, schema=user_schema)\n",
        "df_users.printSchema()\n",
        "df_users.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28l02BlTp1Q1",
        "outputId": "57a8bd5b-5500-4922-c8d4-ff4748a791dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------+--------+---+---------+------+\n",
            "|user_id|    name|age|     city|salary|\n",
            "+-------+--------+---+---------+------+\n",
            "|   U001|Abhishek| 28|Hyderabad| 50000|\n",
            "|   U002|    Neha| 32|    Delhi| 62000|\n",
            "|   U003|    Ravi| 25|Bangalore| 45000|\n",
            "|   U004|   Pooja| 29|   Mumbai| 58000|\n",
            "+-------+--------+---+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Wrong Data\n",
        "raw_data2=[\n",
        "    (\"U005\",\"Amit\",\"Thirty\",\"Chennai\",40000)\n",
        "]\n",
        "\n",
        "df_users = spark.createDataFrame(raw_data2, schema=user_schema)"
      ],
      "metadata": {
        "id": "c_wsLaZPqCu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For Arrays - ArrayType"
      ],
      "metadata": {
        "id": "lIS_WWhFq5sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import ArrayType"
      ],
      "metadata": {
        "id": "u7IsfZiSqXZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interest_data = [\n",
        "    (\"U001\",[\"AI\",\"ML\",\"Cloud\"]),\n",
        "    (\"U002\",[\"Testing\",\"Automation\"]),\n",
        "    (\"U003\",[\"Data Engineering\",\"Spark\",\"Kafka\"]),\n",
        "    (\"U004\",[\"UI/UX\"])\n",
        "]"
      ],
      "metadata": {
        "id": "_cAkp7jirL4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interest_schema = StructType([\n",
        "    StructField(\"user_id\", StringType(),False),\n",
        "    StructField(\"interests\", ArrayType(StringType()),True)\n",
        "])"
      ],
      "metadata": {
        "id": "nHfdcqzcrZWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_interests= spark.createDataFrame(interest_data, schema=interest_schema)\n",
        "df_interests.printSchema()\n",
        "df_interests.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CU4OJy9sbw0",
        "outputId": "1de2290b-b510-47ce-b65c-265d327e6951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- interests: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-------+--------------------+\n",
            "|user_id|           interests|\n",
            "+-------+--------------------+\n",
            "|   U001|     [AI, ML, Cloud]|\n",
            "|   U002|[Testing, Automat...|\n",
            "|   U003|[Data Engineering...|\n",
            "|   U004|             [UI/UX]|\n",
            "+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explode"
      ],
      "metadata": {
        "id": "CbiUZCRZwyUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "\n",
        "df_interests.select (\n",
        "    \"user_id\",\n",
        "    explode(\"interests\").alias(\"interest\")\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imZiFbJQsFEu",
        "outputId": "52749198-0be5-460e-be7d-67d0e95eca64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------------+\n",
            "|user_id|        interest|\n",
            "+-------+----------------+\n",
            "|   U001|              AI|\n",
            "|   U001|              ML|\n",
            "|   U001|           Cloud|\n",
            "|   U002|         Testing|\n",
            "|   U002|      Automation|\n",
            "|   U003|Data Engineering|\n",
            "|   U003|           Spark|\n",
            "|   U003|           Kafka|\n",
            "|   U004|           UI/UX|\n",
            "+-------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MapType"
      ],
      "metadata": {
        "id": "SuoJ_i5usvOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import MapType"
      ],
      "metadata": {
        "id": "NtUJaHrbsxp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_data =[\n",
        "    (\"U001\",{\"mobile\":120,\"laptop\":300}),\n",
        "    (\"U002\",{\"tablet\":80}),\n",
        "    (\"U003\",{\"mobile\":200,\"desktop\":400}),\n",
        "    (\"U004\",{\"laptop\":250})\n",
        "]"
      ],
      "metadata": {
        "id": "UQBlloYJs2lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_schema = StructType ([\n",
        "    StructField(\"user_id\", StringType(), False),\n",
        "    StructField(\"device_usage\", MapType(StringType(), IntegerType()),True)\n",
        "])"
      ],
      "metadata": {
        "id": "eKYqpg-VtQRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_devices = spark.createDataFrame(device_data,device_schema)\n",
        "df_devices.printSchema()\n",
        "df_devices.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1KSd9E3tsv5",
        "outputId": "0ed5328c-9c36-4606-e55a-366288c95e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- device_usage: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: integer (valueContainsNull = true)\n",
            "\n",
            "+-------+-------------------------------+\n",
            "|user_id|device_usage                   |\n",
            "+-------+-------------------------------+\n",
            "|U001   |{mobile -> 120, laptop -> 300} |\n",
            "|U002   |{tablet -> 80}                 |\n",
            "|U003   |{mobile -> 200, desktop -> 400}|\n",
            "|U004   |{laptop -> 250}                |\n",
            "+-------+-------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Nested Schema"
      ],
      "metadata": {
        "id": "2y_yIc0wuTdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nested_data = [\n",
        "    (\"U001\",(\"Hyderabad\",\"Telangana\",500081)),\n",
        "    (\"U002\",(\"Delhi\",\"Delhi\",110001)),\n",
        "    (\"U003\",(\"Bangalore\",\"Karnataka\",560001))\n",
        "]"
      ],
      "metadata": {
        "id": "0_cih_e_ubTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "address_schema = StructType([\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"state\", StringType(), True),\n",
        "    StructField(\"pincode\", IntegerType(), True)\n",
        "\n",
        "])\n",
        "\n",
        "profile_schema = StructType([\n",
        "    StructField(\"user_id\",StringType(),False),\n",
        "    StructField(\"address\", address_schema, True)\n",
        "])"
      ],
      "metadata": {
        "id": "uuRRGj10ufZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_profiles = spark.createDataFrame(nested_data, profile_schema)\n",
        "df_profiles.printSchema()\n",
        "df_profiles.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFz8yJ5svOVX",
        "outputId": "bb0fca59-28e5-4076-fad6-b03cc342ef19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |    |-- state: string (nullable = true)\n",
            " |    |-- pincode: integer (nullable = true)\n",
            "\n",
            "+-------+------------------------------+\n",
            "|user_id|address                       |\n",
            "+-------+------------------------------+\n",
            "|U001   |{Hyderabad, Telangana, 500081}|\n",
            "|U002   |{Delhi, Delhi, 110001}        |\n",
            "|U003   |{Bangalore, Karnataka, 560001}|\n",
            "+-------+------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To select in this nested schema"
      ],
      "metadata": {
        "id": "oB6kSLEivzbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_profiles.select(\n",
        "    \"user_id\",\n",
        "    \"address.city\",\n",
        "    \"address.state\"\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t10sU5Txv3iL",
        "outputId": "cae1de8b-38be-46da-cd08-44519adfbd8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------+\n",
            "|user_id|     city|    state|\n",
            "+-------+---------+---------+\n",
            "|   U001|Hyderabad|Telangana|\n",
            "|   U002|    Delhi|    Delhi|\n",
            "|   U003|Bangalore|Karnataka|\n",
            "+-------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a new column with new data type"
      ],
      "metadata": {
        "id": "asJ6JdE-wM-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df_users.withColumn(\n",
        "    \"salary_int\",\n",
        "    col(\"salary\").cast(\"int\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKOFqXP1wDGb",
        "outputId": "35069e86-744d-479c-d2f6-1f3ce10a7aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[user_id: string, name: string, age: int, city: string, salary: bigint, salary_int: int]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert to date"
      ],
      "metadata": {
        "id": "PRz04pEOxKrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "\n",
        "df_orders.withColumn(\n",
        "    \"order_date\",\n",
        "    to_date(\"order_date\", \"yyyy-mm-dd\")\n",
        ")"
      ],
      "metadata": {
        "id": "rHNiaiffwYnD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}